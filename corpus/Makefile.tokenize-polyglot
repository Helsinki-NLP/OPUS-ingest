# -*-makefile-*-
#
# Makefile targets for tokenization ...
#
#

OPUSTOKENIZER ?= ${OPUSTOOLS}/opus-polyglot-tokenize.py

ifeq (${HPC_HOST},puhti)
  LOAD_ENV ?= module load python-data/3.8 &&
endif


ifndef LANGUAGE
  LANGUAGE=$(firstword ${LANGUAGES})
endif

RAWDIR   = raw/${LANGUAGE}
ifndef XMLFILES
  XMLFILES := $(patsubst raw/%,xml/%,$(shell find ${RAWDIR} -name '*.${XMLEXT}'))
endif

## OLD: for-loop (cannot be parallelized)
##
# tokenize annotate:
# 	for l in ${LANGUAGES}; do \
# 		${MAKE} LANGUAGE=$$l tokenize_files; \
# 	done



## NEW: use flags to indicate finished processes
## --> allow parallelization

TOKENIZE_DONE = ${patsubst %,log/.%.tokenize.done,${LANGUAGES}}
tokenize annotate: ${TOKENIZE_DONE}

${TOKENIZE_DONE}:
	mkdir -p ${dir $@}
	${MAKE} LANGUAGE=${patsubst log/.%.tokenize.done,%,$@} tokenize_files
	mkdir -p ${dir $@}
	touch $@


tokenize_files annotate_files: ${XMLFILES}
	touch log/.${LANGUAGE}.tokenize.done

xml/${LANGUAGE}/%: raw/${LANGUAGE}/%
	mkdir -p $(shell dirname $@)
	${LOAD_ENV} zcat $< |\
	${OPUSTOKENIZER} -l $(LANGUAGE) |\
	gzip -c > $@

clean-xml:
	for l in ${LANGUAGES}; do \
	    if [ -d "xml/$$l" ]; then \
		rm -fr xml/$$l; \
	    fi \
	done
