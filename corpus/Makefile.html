# -*-makefile-*-
#
#
# make the html pages for downloading the corpus
# (including all data formats we provide)


CES      = $(wildcard ${CORPUSXML}/*.xml.gz)
TMX      = $(patsubst ${CORPUSXML}/%.xml.gz,${CORPUSHTML}/%.tmx.gz,$(CES))
MOSES    = $(patsubst ${CORPUSXML}/%.xml.gz,${CORPUSHTML}/%.txt.zip,$(CES))
LANG_TAR = $(patsubst %,${CORPUSHTML}/%.tar.gz,${LANGUAGES})
LANG_RAW = $(patsubst %,${CORPUSHTML}/%.raw.tar.gz,${LANGUAGES})


## strict = bitexts with "high-quality" alignments only
## (1:1, hunalign link score > 1)

TMX_STRICT    = $(patsubst ${CORPUSXML}/%.xml.gz,${CORPUSHTML}/%.strict.tmx.gz,$(CES))
MOSES_STRICT  = $(patsubst ${CORPUSXML}/%.xml.gz,${CORPUSHTML}/%.strict.txt.zip,$(CES))


MONO_TOK = $(patsubst %,${CORPUSHTML}/mono/${CORPUS}.%.gz, ${LANGUAGES})
MONO_RAW = $(patsubst %,${CORPUSHTML}/mono/${CORPUS}.raw.%.gz, ${LANGUAGES})

FREQ_COUNTS = $(patsubst %,${CORPUSHTML}/freq/${CORPUS}.%.gz, ${LANGUAGES})
ALG_SAMPLES = $(patsubst ${CORPUSXML}/%.xml.gz,${CORPUSHTML}/%_sample.html, ${CES})
CORPUS_SAMPLES = $(patsubst %,${CORPUSHTML}/%_sample.html, ${LANGUAGES})


CES_INFO = $(patsubst %.xml.gz,%.info,${CES})
TXT_INFO = $(patsubst ${CORPUSHTML}/%.txt.zip,${CORPUSXML}/%.txt.info,${MOSES})
TMX_INFO = $(patsubst ${CORPUSHTML}/%.tmx.gz,${CORPUSXML}/%.tmx.info,${TMX})
LANG_INFO = $(patsubst %,${CORPUSXML}/%.info,${LANGUAGES})


MAKEHTML   = ${TOOLS}/opus/make-download-page.pl
TAB2TMX    = ${UPLUGHOME}/tools/tab2tmx
OPUS2MOSES = $(UPLUGHOME)/tools/xces2moses


html: 	download-dirs \
	lang_tok_tar lang_raw_tar \
	mono_tok mono_raw \
	moses tmx \
	info \
	pack \
	${OPUSPUB}/${CORPUS}.php

refresh-html:
	rm -f ${OPUSPUB}/${CORPUS}.php
	rm -f ${CORPUSHTML}/*sample.html
	touch $(CES)
	make html


download-dirs: ${CORPUS} ${CORPUSHTML} ${CORPUSHTML}/xml

webpage: ${OPUSPUB}/${CORPUS}.php


${CORPUS}:
	ln -s xml $@

${CORPUSHTML}:
	mkdir -p $@

${CORPUSHTML}/xml:
	ln -s $(CORPUSXML) $@

#  CITENOTE=Please <a href="http://opus.lingfil.uu.se/RANLP_V.txt">cite the following article</a> if you use any part of the corpus in your own work:<br/> J\&ouml;rg Tiedemann, 2009, <a href="http://stp.lingfil.uu.se/~joerg/published/ranlp-V.pdf">News from OPUS - A Collection of Multilingual Parallel Corpora with Tools and Interfaces</a>. In N. Nicolov and K. Bontcheva and G. Angelova and R. Mitkov (eds.) Recent Advances in Natural Language Processing (vol V), pages 237-248, John Benjamins, Amsterdam/Philadelphia<br/>

ifndef CITENOTE
  CITENOTE=Please <a href="http://opus.lingfil.uu.se/LREC2012.txt">cite the following article</a> if you use any part of the corpus in your own work:<br/> J\&ouml;rg Tiedemann, 2012, <a href="http://www.lrec-conf.org/proceedings/lrec2012/pdf/463_Paper.pdf"><i>Parallel Data, Tools and Interfaces in OPUS.</i></a> In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012)<br/>
endif


## 2015-08-16: do not depend on packed archive anymore
# ${OPUSHTML}/${CORPUS}/${CORPUS}${VERSION}.tar.gz

${OPUSPUB}/${CORPUS}.php: 
	mkdir -p $(shell dirname $@)
	if [ ! -e ${CORPUS} ]; then ln -s xml ${CORPUS}; fi
	if [ ! -e ${OPUSHTML}/${CORPUS} ]; then mkdir ${OPUSHTML}/${CORPUS}; fi
	if [ ! -e ${OPUSHTML}/${CORPUS}/xml ]; then ln -s ${CORPUSHOME}/xml ${OPUSHTML}/${CORPUS}/xml; fi
	if [ ! -e ${OPUSPUB}/${CORPUS} ]; then ln -s ${OPUSHTML}/${CORPUS} ${OPUSPUB}/${CORPUS}; fi
	${MAKEHTML} -e $(ALGEXT:.gz=) ${CORPUS} ${VERSION}|\
	sed -e 's#<h3>Download</h3>#<h3>Download</h3>${EXTRAHTML}#' \
	    -e "s#${CORPUS}.tar.gz#${CORPUS}${VERSION}.tar.gz#g" \
	    -e 's#<h3>Download</h3>#${CITENOTE}<h3>Download</h3>#' \
	    -e 's#<h1>${CORPUS}${VERSION}</h1>#<h1>${CORPUS}</h1>#' \
	    -e 's#<h1>${CORPUS}</h1>#<h1>${CORPUS}</h1>${SRCHTML}#' > $@



## make an archive with all xml-files!

pack:
	${MAKE} ${OPUSHTML}/${CORPUS}/${CORPUS}${VERSION}.tar.gz

## only pack parallel data files (tokenized and untokenized)
## --> skip non-aligned files
## --> problem: non-aligned files may be interesting for language modeling!
##              (a lot of files are lost in this way in OpenSubtitles!)

${OPUSHTML}/${CORPUS}/${CORPUS}${VERSION}.tar.files: $(CES)
	mkdir -p $(shell dirname $@)
	zcat $^ | \
	tr " " "\n" | \
	egrep '(from|to)Doc' | \
	cut -f2 -d '"' | \
	sort | uniq > $@.basenames
	sed 's#^#xml/#' < $@.basenames >>$@
	sed 's#^#raw/#' < $@.basenames >>$@
	rm -f $@.basenames
	find ${CORPUSXML} -maxdepth 1 -name '*.xml.gz' | \
	sed 's#${CORPUSXML}#xml#' >> $@
	if [ -e README ]; then echo 'README' >> $@; fi
	if [ -e CHANGES ]; then echo 'CHANGES' >> $@; fi


${OPUSHTML}/${CORPUS}/${CORPUS}${VERSION}.tar.gz: ${OPUSHTML}/${CORPUS}/${CORPUS}${VERSION}.tar.files
	rm -f $@
	mkdir -p $(shell dirname $@)
	-tar -h -T $< --transform='s#^#${CORPUS}/#' -czf $@

##	rm -f ${OPUSHTML}/${CORPUS}/${CORPUS}${VERSION}.tar.files


# ### alternative: just pack everything in xml and raw!

# ${OPUSHTML}/${CORPUS}/${CORPUS}${VERSION}.tar.gz: $(CES)
# 	rm -f $@
# 	mkdir -p $(shell dirname $@)
# 	-tar --transform 's#^#${CORPUS}/#' -chzf $(shell basename $@) xml raw
# 	mv $(shell basename $@) $@



#----------------------------------------------------------------------------
# pack all language files in tar-archives
#----------------------------------------------------------------------------

# # old version: just pack the tokenized versions

# lang_tar: ${LANG_TAR}

# ${LANG_TAR}: ${CORPUSHTML}/%.tar.gz: ${CORPUS}/%
# 	find $</ -name '*.xml.gz' > $<.files
# 	-tar -T $<.files -czf $@
# 	rm -f $<.files

# tokenized version (same as above but file path including /xml/)

lang_tar lang_tok_tar: ${LANG_TAR}

${LANG_TAR}: ${CORPUSHTML}/%.tar.gz: ${CORPUSXML}/%
	find $</ -name '*.xml.gz' > $<.files
	-tar -T $<.files -P --transform='s#${CORPUSXML}#${CORPUS}/xml#' -czf $@
	rm -f $<.files

# raw corpus files

lang_raw_tar: ${LANG_RAW}

${LANG_RAW}: ${CORPUSHTML}/%.raw.tar.gz: ${CORPUSRAW}/%
	find $</ -name '*.xml.gz' > $<.files
	-tar -T $<.files -P --transform='s#${CORPUSRAW}#${CORPUS}/raw#' -czf $@
	rm -f $<.files


#----------------------------------------------------------------------------
# make monolingual plain text files
#----------------------------------------------------------------------------

mono_tok: ${MONO_TOK}
mono_raw: ${MONO_RAW}

CORPUS_EXT = xml

# monolingual data for language modeling
# (NEW: only real files, no symlinks!)

${CORPUSHTML}/mono/${CORPUS}.%.gz: ${CORPUSXML}/%
	mkdir -p `dirname $@`
	find $</ -name '*.${CORPUS_EXT}.gz' -type f | \
	xargs zcat | \
	perl ${TOOLS}/opus/xml2text.pl | \
	sed 's/  */ /g;s/^ *//;s/ *$$//' |\
	gzip -c > $@


${CORPUSHTML}/mono/${CORPUS}.raw.%.gz: ${CORPUSRAW}/%
	mkdir -p `dirname $@`
	find $</ -name '*.${CORPUS_EXT}.gz' -type f | \
	xargs zcat | \
	perl -p -e 's/[\x00-\x08\x0B\x0C\x0E-\x1F]//g' |\
	perl ${TOOLS}/opus/rawxml2text.pl | \
	sed 's/  */ /g;s/^ *//;s/ *$$//' |\
	gzip -c > $@



#----------------------------------------------------------------------------
# frequency counts for lowercased tokens
#----------------------------------------------------------------------------

.PHONY: freq_counts
freq_counts: ${FREQ_COUNTS}

${CORPUSHTML}/freq/${CORPUS}.%.gz: ${CORPUSHTML}/mono/${CORPUS}.%.gz
	mkdir -p `dirname $@`
	zcat $< | \
	perl -e 'binmode(STDIN,":utf8");binmode(STDOUT,":utf8");while(<>){$$_=lc($$_);print;}' |\
	tr ' ' "\n" | \
	sort | uniq -c | sort -nr | \
	gzip -c > $@


## not good enough for unicode:
##	tr '[:upper:]' '[:lower:]'

#----------------------------------------------------------------------------
# alignment sample files
#----------------------------------------------------------------------------

.PHONY: alg_samples
alg_samples: ${ALG_SAMPLES}

# -N '\/0\/' is used to filter out some strange files in OpenSubtitles2012
# which would be used for many sample files (year = 0)
# (they look messy and should actually be removed from the corpus)

${ALG_SAMPLES}: ${CORPUSHTML}/%_sample.html: ${CORPUSXML}/%.xml.gz
	mkdir -p `dirname $@`
	$(UPLUGTOOLS)/uplug-readalign \
		-h -m 100 \
		-N '\/0\/' \
	$< > $@


.PHONY: corpus_samples
corpus_samples: ${CORPUS_SAMPLES}

# -N '\/0\/' is used to filter out some strange files in OpenSubtitles2012
# which would be used for many sample files (year = 0)
# (they look messy and should actually be removed from the corpus)

${CORPUS_SAMPLES}: ${CORPUSHTML}/%_sample.html: ${CORPUSXML}/%
	echo '<html><head></head><body><pre>' >$@
	find $</ -name '*.xml.gz' | \
	xargs zcat | head -100 | recode utf8..html >> $@
	echo '</pre></body></html>' >> $@

#----------------------------------------------------------------------------
# convert all bitexts to TMX
#----------------------------------------------------------------------------

# create TMX files from plain text files (Moses format)
# TMX files contain only unique translation units!
# --> use sort/uniq
# --> number alignments first to keep textual order!

tmx: ${CORPUSHTML} $(TMX)

tmx-strict: ${CORPUSHTML} $(TMX_STRICT)

# $(TMX): 

%.tmx.gz: %.txt.zip
	unzip $<
	( S=$(firstword $(subst -, ,$(firstword $(subst ., ,$(notdir $<)))));\
	  T=$(lastword $(subst -, ,$(firstword $(subst ., ,$(notdir $<)))));\
	  P=$$S-$$T; \
	  SEXT=$$S; TEXT=$$T; \
	  if [ "$$SEXT" == "$$TEXT" ]; then SEXT=$${SEXT}1;TEXT=$${TEXT}2; fi; \
	  paste ${CORPUS}.$$P.$$SEXT ${CORPUS}.$$P.$$TEXT |\
	  sed = - | sed 'N;s/\n/\t/' | sort -k 2 | uniq -f 1 | sort -n |\
	  cut -f2,3 |\
	  $(TAB2TMX) -s $$S -t $$T |\
	  gzip -c > $@; \
	  rm -f ${CORPUS}.$$P.$$SEXT ${CORPUS}.$$P.$$TEXT ${CORPUS}.$$P.ids; )


#----------------------------------------------------------------------------
# convert all bitexts to Moses format
#----------------------------------------------------------------------------


moses: ${CORPUSHTML} $(MOSES)

$(MOSES): ${CORPUSHTML}/%.txt.zip: ${CORPUSXML}/%.xml.gz
	( S=$(firstword $(subst -, ,$(patsubst ${CORPUSXML}/%.xml.gz,%,$<))); \
	  T=$(lastword $(subst -, ,$(patsubst ${CORPUSXML}/%.xml.gz,%,$<))); \
	  P=$$S-$$T; \
	  if [ "$$S" == "$$T" ]; then S=$${S}1;T=$${T}2; fi; \
	  $(OPUS2MOSES) -d ${CORPUSRAW} -s $$S -t $$T \
		-P ${CORPUS}.$$P.ids \
		$< ${CORPUS}.$$P; \
	  rm -f $@; \
	  sed 's/  */ /g' < ${CORPUS}.$$P.$$S > ${CORPUS}.$$P.$$S.tmp; \
	  sed 's/  */ /g' < ${CORPUS}.$$P.$$T > ${CORPUS}.$$P.$$T.tmp; \
	  mv ${CORPUS}.$$P.$$S.tmp ${CORPUS}.$$P.$$S; \
	  mv ${CORPUS}.$$P.$$T.tmp ${CORPUS}.$$P.$$T; \
	  zip $@ ${CORPUS}.$$P.$$S ${CORPUS}.$$P.$$T ${CORPUS}.$$P.ids; \
	  rm -f ${CORPUS}.$$P.$$S ${CORPUS}.$$P.$$T ${CORPUS}.$$P.ids; )


moses-strict: ${CORPUSHTML} $(MOSES_STRICT)

$(MOSES_STRICT): ${CORPUSHTML}/%.strict.txt.zip: ${CORPUSXML}/%.xml.gz
	uplug-readalign -c 1 -S 1 -T 1 -l $< > $(<:gz=11)
	( S=$(firstword $(subst -, ,$(patsubst ${CORPUSXML}/%.xml.gz,%,$<))); \
	  T=$(lastword $(subst -, ,$(patsubst ${CORPUSXML}/%.xml.gz,%,$<))); \
	  P=$$S-$$T; \
	  if [ "$$S" == "$$T" ]; then S=$${S}1;T=$${T}2; fi; \
	  $(OPUS2MOSES) -d ${CORPUSRAW} -s $$S -t $$T \
		-P ${CORPUS}.$$P.ids \
		$(<:gz=11) ${CORPUS}.$$P; \
	  rm -f $@; \
	  zip $@ ${CORPUS}.$$P.$$S ${CORPUS}.$$P.$$T ${CORPUS}.$$P.ids; \
	  rm -f ${CORPUS}.$$P.$$S ${CORPUS}.$$P.$$T ${CORPUS}.$$P.ids; )
	rm -f $(<:gz=11)


# create bitext info files (some basic statistics)

info: lang_info ces_info txt_info tmx_info


lang_info: ${LANG_INFO}

${LANG_INFO}: ${CORPUSXML}/%.info: ${CORPUSXML}/%
	find $</ -name '*.xml.gz' -type f | wc -l > $@
	find $</ -name '*.xml.gz' -type f | \
	xargs zcat | grep '</s>' | wc -l >> $@
	find $</ -name '*.xml.gz' -type f | \
	xargs zcat | grep '</w>' | wc -l >> $@


ces_info: ${CES_INFO}

${CES_INFO}: %.info: %.xml.gz
	zgrep 'fromDoc' $< | wc -l > $@
	zgrep 'xtargets' $< | wc -l >> $@
	( cd ${CORPUSXML}; \
	  zgrep 'fromDoc' $< | \
	  tr ' ' "\n" | grep 'fromDoc' | cut -f2 -d '"' |\
	  xargs zcat | \
	  grep '</w>' | wc -l >> $@ )
	( cd ${CORPUSXML}; \
	  zgrep 'toDoc' $< | \
	  tr ' ' "\n" | grep 'toDoc' | cut -f2 -d '"' |\
	  xargs zcat | \
	  grep '</w>' | wc -l >> $@ )


txt_info: ${TXT_INFO}

${TXT_INFO}: ${CORPUSXML}/%.txt.info: ${CORPUSHTML}/%.txt.zip
	-unzip -d . $<
	(S=$(firstword $(subst -, ,$(patsubst ${CORPUSXML}/%.txt.info,%,$@)));\
	 T=$(lastword $(subst -, ,$(patsubst ${CORPUSXML}/%.txt.info,%,$@)));\
	  P=$$S-$$T; \
	  if [ "$$S" == "$$T" ]; then S=$${S}1;T=$${T}2; fi; \
	  if [ ! -e ${CORPUS}.$$P.$$S ]; then \
		find home -name "*$$P.$$S" -exec mv {} ${CORPUS}.$$P.$$S \; ; \
		find home -name "*$$P.$$T" -exec mv {} ${CORPUS}.$$P.$$T \; ; \
		rm -f $< ;\
		zip $< ${CORPUS}.$$P.$$S ${CORPUS}.$$P.$$T; \
	  fi; \
	  wc -l < ${CORPUS}.$$P.$$S > $(CORPUSXML)/$$P.txt.info; \
	  wc -w < ${CORPUS}.$$P.$$S >> $(CORPUSXML)/$$P.txt.info; \
	  wc -w < ${CORPUS}.$$P.$$T >> $(CORPUSXML)/$$P.txt.info; \
	  rm -f *$$P.$$S *$$P.$$T *$$P.ids; )


tmx_info: ${TMX_INFO}

${TMX_INFO}: ${CORPUSXML}/%.tmx.info: ${CORPUSHTML}/%.tmx.gz
	(S=$(firstword $(subst -, ,$(patsubst ${CORPUSXML}/%.tmx.info,%,$@)));\
	 T=$(lastword $(subst -, ,$(patsubst ${CORPUSXML}/%.tmx.info,%,$@)));\
	 zgrep '</tu>' $< | wc -l > $@; \
	 zgrep "xml:lang=\"$$S\"" $< | \
	  	sed 's|^.*<seg>||;s|</seg>.*$$||;' | \
	  	wc -w >> $@; \
	 zgrep "xml:lang=\"$$T\"" $< | \
	  	sed 's|^.*<seg>||;s|</seg>.*$$||;' | \
	  	wc -w >> $@; )
